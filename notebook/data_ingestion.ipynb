{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de73111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7495616",
   "metadata": {},
   "source": [
    "# constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e602ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_support.utils import load_yaml\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "CONFIG=load_yaml(\"config/config.yaml\")\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConstants:\n",
    "    GOOGLE_EMBEDDING_MODEL_NAME=CONFIG.MODELS.EMBEDDING.GOOGLE\n",
    "    HUGGINGFACE_EMBEDDING_MODEL_NAME=CONFIG.MODELS.EMBEDDING.HUGGINGFACE\n",
    "    DATA_DIR_NAME=CONFIG.DATA_INGESTION.DATA_DIR_NAME\n",
    "    DATA_FILE_NAME=CONFIG.DATA_INGESTION.DATA_FILE_NAME\n",
    "    MONGODB_DATABASE_NAME=CONFIG.DATA_INGESTION.MONGODB_DATABASE_NAME\n",
    "    MONGODB_COLLECTION_NAME=CONFIG.DATA_INGESTION.MONGODB_COLLECTION_NAME\n",
    "    ASTRADB_KEYSPACE_NAME=CONFIG.DATA_INGESTION.ASTRADB_KEYSPACE_NAME\n",
    "    ASTRADB_COLLECTION_NAME=CONFIG.DATA_INGESTION.ASTRADB_COLLECTION_NAME\n",
    "    ASTRADB_K_VALUE=int(CONFIG.DATA_INGESTION.ASTRADB_K_VALUE)\n",
    "    ASTRADB_ENDPOINT=os.getenv(\"ASTRADB_ENDPOINT\")\n",
    "    ASTRADB_TOKEN=os.getenv(\"ASTRADB_TOKEN\")\n",
    "    MONGODB_URI=os.getenv(\"MONGODB_URI\")\n",
    "    GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "    GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "    HF_TOKEN=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"GOOGLE_EMBEDDING_MODEL_NAME:{DataIngestionConstants.GOOGLE_EMBEDDING_MODEL_NAME}\")\n",
    "print(f\"HUGGINGFACE_EMBEDDING_MODEL_NAME:{DataIngestionConstants.HUGGINGFACE_EMBEDDING_MODEL_NAME}\")\n",
    "print(f\"DATA_DIR_NAME:{DataIngestionConstants.DATA_DIR_NAME}\")\n",
    "print(f\"DATA_FILE_NAME:{DataIngestionConstants.DATA_FILE_NAME}\")\n",
    "print(f\"MONGODB_DATABASE_NAME:{DataIngestionConstants.MONGODB_DATABASE_NAME}\")\n",
    "print(f\"MONGODB_COLLECTION_NAME:{DataIngestionConstants.MONGODB_COLLECTION_NAME}\")\n",
    "print(f\"ASTRADB_KEYSPACE_NAME:{DataIngestionConstants.ASTRADB_KEYSPACE_NAME}\")\n",
    "print(f\"ASTRADB_COLLECTION_NAME:{DataIngestionConstants.ASTRADB_COLLECTION_NAME}\")\n",
    "print(f\"ASTRADB_K_VALUE:{DataIngestionConstants.ASTRADB_K_VALUE}\")\n",
    "print(f\"ASTRADB_ENDPOINT:{DataIngestionConstants.ASTRADB_ENDPOINT}\")\n",
    "print(f\"ASTRADB_TOKEN:{DataIngestionConstants.ASTRADB_TOKEN}\")\n",
    "print(f\"MONGODB_URI:{DataIngestionConstants.MONGODB_URI}\")\n",
    "print(f\"GROQ_API_KEY:{DataIngestionConstants.GROQ_API_KEY}\")\n",
    "print(f\"GOOGLE_API_KEY:{DataIngestionConstants.GOOGLE_API_KEY}\")\n",
    "print(f\"HF_TOKEN:{DataIngestionConstants.HF_TOKEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6004639c",
   "metadata": {},
   "source": [
    "# entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee50db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestion:\n",
    "    GOOGLE_EMBEDDING_MODEL_NAME:str\n",
    "    HUGGINGFACE_EMBEDDING_MODEL_NAME:str\n",
    "    DATA_DIR_PATH:Path\n",
    "    DATA_FILE_PATH:str\n",
    "    MONGODB_DATABASE_NAME:str\n",
    "    MONGODB_COLLECTION_NAME:str\n",
    "    ASTRADB_KEYSPACE_NAME:str\n",
    "    ASTRADB_COLLECTION_NAME:str\n",
    "    ASTRADB_K_VALUE:int\n",
    "    ASTRADB_ENDPOINT:str\n",
    "    ASTRADB_TOKEN:str\n",
    "    MONGODB_URI:str\n",
    "    GROQ_API_KEY:str\n",
    "    GOOGLE_API_KEY:str\n",
    "    HF_TOKEN:str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca7bae2",
   "metadata": {},
   "source": [
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    GOOGLE_EMBEDDING_MODEL_NAME=DataIngestionConstants.GOOGLE_EMBEDDING_MODEL_NAME\n",
    "    HUGGINGFACE_EMBEDDING_MODEL_NAME=DataIngestionConstants.HUGGINGFACE_EMBEDDING_MODEL_NAME\n",
    "    DATA_DIR_PATH=Path(DataIngestionConstants.DATA_DIR_NAME)\n",
    "    DATA_FILE_PATH=os.path.join(DATA_DIR_PATH, DataIngestionConstants.DATA_FILE_NAME)\n",
    "    MONGODB_DATABASE_NAME=DataIngestionConstants.MONGODB_DATABASE_NAME\n",
    "    MONGODB_COLLECTION_NAME=DataIngestionConstants.MONGODB_COLLECTION_NAME\n",
    "    ASTRADB_KEYSPACE_NAME=DataIngestionConstants.ASTRADB_KEYSPACE_NAME\n",
    "    ASTRADB_COLLECTION_NAME=DataIngestionConstants.ASTRADB_COLLECTION_NAME\n",
    "    ASTRADB_K_VALUE=DataIngestionConstants.ASTRADB_K_VALUE\n",
    "    ASTRADB_ENDPOINT=DataIngestionConstants.ASTRADB_ENDPOINT\n",
    "    ASTRADB_TOKEN=DataIngestionConstants.ASTRADB_TOKEN\n",
    "    MONGODB_URI=DataIngestionConstants.MONGODB_URI\n",
    "    GROQ_API_KEY=DataIngestionConstants.GROQ_API_KEY\n",
    "    GOOGLE_API_KEY=DataIngestionConstants.GOOGLE_API_KEY\n",
    "    HF_TOKEN=DataIngestionConstants.HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"GOOGLE_EMBEDDING_MODEL_NAME:{DataIngestionConfig.GOOGLE_EMBEDDING_MODEL_NAME}\")\n",
    "print(f\"HUGGINGFACE_EMBEDDING_MODEL_NAME:{DataIngestionConfig.HUGGINGFACE_EMBEDDING_MODEL_NAME}\")\n",
    "print(f\"DATA_DIR_PATH:{DataIngestionConfig.DATA_DIR_PATH}\")\n",
    "print(f\"DATA_FILE_PATH:{DataIngestionConfig.DATA_FILE_PATH}\")\n",
    "print(f\"MONGODB_DATABASE_NAME:{DataIngestionConfig.MONGODB_DATABASE_NAME}\")\n",
    "print(f\"MONGODB_COLLECTION_NAME:{DataIngestionConfig.MONGODB_COLLECTION_NAME}\")\n",
    "print(f\"ASTRADB_KEYSPACE_NAME:{DataIngestionConfig.ASTRADB_KEYSPACE_NAME}\")\n",
    "print(f\"ASTRADB_COLLECTION_NAME:{DataIngestionConfig.ASTRADB_COLLECTION_NAME}\")\n",
    "print(f\"ASTRADB_K_VALUE:{DataIngestionConfig.ASTRADB_K_VALUE}\")\n",
    "print(f\"ASTRADB_ENDPOINT:{DataIngestionConfig.ASTRADB_ENDPOINT}\")\n",
    "print(f\"ASTRADB_TOKEN:{DataIngestionConfig.ASTRADB_TOKEN}\")\n",
    "print(f\"MONGODB_URI:{DataIngestionConfig.MONGODB_URI}\")\n",
    "print(f\"GROQ_API_KEY:{DataIngestionConfig.GROQ_API_KEY}\")\n",
    "print(f\"GOOGLE_API_KEY:{DataIngestionConfig.GOOGLE_API_KEY}\")\n",
    "print(f\"HF_TOKEN:{DataIngestionConfig.HF_TOKEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f08f74",
   "metadata": {},
   "source": [
    "# components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec35e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from customer_support.utils import create_dirs, load_yaml\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from customer_support.exception import CustomException\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from customer_support.logger import logging\n",
    "from dataclasses import dataclass\n",
    "from pymongo import MongoClient\n",
    "from box import ConfigBox\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionComponents:\n",
    "    __data_ingestion_config:DataIngestion\n",
    "\n",
    "    @staticmethod\n",
    "    def collection_to_dataframe(collection)->pd.DataFrame:\n",
    "        \"\"\"converts mongodb collection into pandas dataframe\n",
    "\n",
    "        Args:\n",
    "            collection (mongodb collection): collection which needs to convert into dataframe\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"In collection_to_dataframe\")\n",
    "\n",
    "            # collection mongodb collection \n",
    "            df = pd.DataFrame(collection.find())\n",
    "            logging.info(\"data successfully converted (mongodb collection ===> pandas DataFrame)\")\n",
    "\n",
    "            # converting mongodb collection into pandas dataframe\n",
    "            df = df.drop(\"_id\", axis = 1)\n",
    "\n",
    "            logging.info(\"Out collection_to_dataframe\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    @staticmethod\n",
    "    def validate_data(data:pd.DataFrame, old_schema:ConfigBox)->bool:\n",
    "        \"\"\"validates the data based on provided schema\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): dataframe object for validation\n",
    "            schema (ConfigBox): configbox object as schema for validation\n",
    "\n",
    "        Returns:\n",
    "            bool: True if schema matches else False\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"In validate_data\")\n",
    "\n",
    "            # create required vars\n",
    "            schema = dict()\n",
    "            columns_with_dtype = dict()\n",
    "            numerical_columns = list()\n",
    "\n",
    "            for col in data.columns:\n",
    "                columns_with_dtype[col] = str(data[col].dtype)\n",
    "                if data[col].dtype!=\"O\":\n",
    "                    numerical_columns.append(col)\n",
    "\n",
    "            schema[\"columns\"] = columns_with_dtype\n",
    "            schema[\"numerical_columns\"] = numerical_columns\n",
    "\n",
    "            logging.info(\"regenerated schema\")\n",
    "\n",
    "            new_schema=ConfigBox(schema)\n",
    "            status= True if old_schema==new_schema else False\n",
    "            logging.info(f\"validation status:{status}\")\n",
    "\n",
    "            logging.info(\"Out validate_data\")\n",
    "            return status\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def collect_data(self)->None:\n",
    "        \"\"\"collects data from data base and saves locally\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"In collect_data\")\n",
    "\n",
    "            # create required dirs\n",
    "            create_dirs(self.__data_ingestion_config.DATA_DIR_PATH)\n",
    "\n",
    "            # creating environment variable HUGGINGFACE_API_TOKEN\n",
    "            os.environ[\"HUGGINGFACE_API_TOKEN\"] = self.__data_ingestion_config.HF_TOKEN\n",
    "            \n",
    "            # connecting to mongodb\n",
    "            MONGODB_URI = self.__data_ingestion_config.MONGODB_URI\n",
    "            client = MongoClient(MONGODB_URI)\n",
    "            client.admin.command('ping')\n",
    "            logging.info(\"You are successfully connected to MongoDB!\")\n",
    "\n",
    "            database_name = self.__data_ingestion_config.MONGODB_DATABASE_NAME\n",
    "            collection_name = self.__data_ingestion_config.MONGODB_COLLECTION_NAME\n",
    "            \n",
    "            # collection mongodb collection\n",
    "            collection = client[database_name][collection_name]\n",
    "\n",
    "            # converting mongodb collection into pandas dataframe\n",
    "            self.data_frame = self.collection_to_dataframe(collection)\n",
    "            logging.info(f\"collected data from mongodb, DATABASE: {database_name} and COLLECTION: {collection_name}\")\n",
    "            \n",
    "            # saving data into local file path\n",
    "            file_path = self.__data_ingestion_config.DATA_FILE_PATH\n",
    "            self.data_frame.to_csv(file_path, index=False, header=True)\n",
    "            logging.info(f\"Data saved at {file_path}\")\n",
    "\n",
    "            logging.info(\"Out collect_data\")\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def load_embedding_model(self)->None:\n",
    "        \"\"\"loads the embedding model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"In load_embeddings\")\n",
    "            try:\n",
    "                model_name = self.__data_ingestion_config.GOOGLE_EMBEDDING_MODEL_NAME\n",
    "                self.embeddings = GoogleGenerativeAIEmbeddings(model=model_name)\n",
    "            except:\n",
    "                model_name = self.__data_ingestion_config.HUGGINGFACE_EMBEDDING_MODEL_NAME\n",
    "                self.embeddings = HuggingFaceEmbeddings(\n",
    "                    model_name = model_name, \n",
    "                    model_kwargs = {\"device\": \"cpu\"}, \n",
    "                    encode_kwargs = {\"normalize_embeddings\": True}\n",
    "                )\n",
    "            logging.info(f\"loaded embedding model {{{model_name}}}\")\n",
    "            logging.info(\"Out load_embeddings\")\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def format_data_for_insertion(self)->list[Document]:\n",
    "        \"\"\"converts data into required format for insertion in vector store\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"In format_data_for_insertion\")\n",
    "\n",
    "            docs = []\n",
    "            columns = list(self.data_frame.columns)\n",
    "            columns.remove(\"review\")\n",
    "            for _, row in self.data_frame.iterrows():\n",
    "                metadata = {col:row[col] for col in columns}\n",
    "                doc = Document(page_content=row[\"review\"], metadata=metadata)\n",
    "                docs.append(doc)\n",
    "            logging.info(f\"total number of records formated {{{len(docs)}}}\")\n",
    "                \n",
    "            logging.info(\"Out format_data_for_insertion\")\n",
    "            return docs\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            raise\n",
    "\n",
    "    def get_vector_store(self)->AstraDBVectorStore:\n",
    "        \"\"\"returns dict of astradb config\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"In get_vector_store\")\n",
    "\n",
    "            vstore = AstraDBVectorStore(\n",
    "                collection_name=self.__data_ingestion_config.ASTRADB_COLLECTION_NAME,\n",
    "                embedding=self.embeddings,\n",
    "                api_endpoint=self.__data_ingestion_config.ASTRADB_ENDPOINT,\n",
    "                token=self.__data_ingestion_config.ASTRADB_TOKEN,\n",
    "                namespace=self.__data_ingestion_config.ASTRADB_KEYSPACE_NAME,\n",
    "            )\n",
    "            logging.info(\"Out get_vector_store\")\n",
    "            return vstore\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            raise\n",
    "        \n",
    "    def insert_data(self)->int:\n",
    "        \"\"\"Inserts data into vectorstore\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"In insert_data\")\n",
    "\n",
    "            # create vector store instance\n",
    "            self.vector_store = self.get_vector_store()\n",
    "\n",
    "            # format the data into list of document object\n",
    "            docs = self.format_data_for_insertion()\n",
    "\n",
    "            # insert documents into vector store\n",
    "            total_records_inserted = len(self.vector_store.add_documents(documents = docs))\n",
    "            logging.info(f\"total number of records inserted in vectorstore {{{total_records_inserted}}}\")\n",
    "            \n",
    "            logging.info(\"Out insert_data\")\n",
    "            return total_records_inserted\n",
    "        except Exception as e:\n",
    "            logging.exception(e)\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def main(self):\n",
    "        self.collect_data()\n",
    "        schema=load_yaml(\"schema/schema.yaml\")\n",
    "        status=self.validate_data(self.data_frame, schema)\n",
    "        if status:\n",
    "            self.load_embedding_model()\n",
    "            self.insert_data()\n",
    "        else:\n",
    "            logging.info(f\"collected data and provided schema given {{status:'\\{status}'\\}}, skipping the upcomming data ingestion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42114ca",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa421d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customer_support.logger import logging\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class DataIngestionPipeline:\n",
    "\n",
    "    def run(self)->dict:\n",
    "        \"\"\"runs the full pipeline of training\n",
    "\n",
    "        Returns:\n",
    "            dict: output of all initialized objects as a single dict \n",
    "        \"\"\"\n",
    "        logging.info(\"In TrainingPipeline\")\n",
    "\n",
    "        # data ingestion\n",
    "        data_ingestion=DataIngestionComponents(DataIngestionConfig)\n",
    "        data_ingestion.main()\n",
    "        retriever = data_ingestion.get_vector_store().as_retriever()\n",
    "\n",
    "\n",
    "        logging.info(\"Out TrainingPipeline\")\n",
    "        return {\n",
    "            \"retriever\":retriever\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e3b58",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    training_pipeline = DataIngestionPipeline()\n",
    "    training_outputs = training_pipeline.run()\n",
    "    retriever = training_outputs[\"retriever\"]\n",
    "    query = \"Can you tell me the low budget headphone?\"\n",
    "    k=DataIngestionConfig.ASTRADB_K_VALUE\n",
    "    results=retriever.invoke(query, k=k)\n",
    "    for res in results:\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a207d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
